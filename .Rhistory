flab <- flabels[which(feats==split[1])]
if (length(split) > 1) {
vlab <- vlabels[which(vals==split[2])]
return(paste0(flab, " (", vlab, ")"))
} else {
return(flab)
}
}
# data -------------------
dep <- haven::read_dta("data/explore/depression/Qualtrics_data.dta")
df <- dep[, -c(1:20, which(colnames(dep)=="vote18"))]
X <- df[, sapply(1:ncol(df), FUN=function(i) length(unlist(unique(df[, i])))==2)]
X$depression_low <- discretize(df$depression, 1/3)
X$depression_lowmed <- discretize(df$depression, 2/3)
#X$depression_medhigh <- as.numeric(!X$depression_low)
X$depression_high <- as.numeric(!X$depression_lowmed)
#X$depression_med <- as.numeric(X$depression_lowmed & !X$depression_low)
X$age_low <- discretize(df$age, 1/3)
X$age_lowmed <- discretize(df$age, 2/3)
#X$age_medhigh <- as.numeric(!X$age_low)
X$age_high <- as.numeric(!X$age_lowmed)
#X$age_med <- as.numeric(X$age_lowmed & !X$age_low)
X$educ_low <- as.numeric(df$educ <= 2)
X$educ_lowmed <- as.numeric(df$educ <= 5)
#X$educ_medhigh <- as.numeric(!X$educ_low)
X$educ_high <- as.numeric(!X$educ_lowmed)
#X$educ_med <- as.numeric(X$educ_lowmed & !X$educ_low)
X$inc_low <- as.numeric(df$income <= 4)
X$inc_lowmed <- as.numeric(df$income <= 9)
#X$inc_medhigh <- as.numeric(!X$inc_low)
X$inc_high <- as.numeric(!X$inc_lowmed)
#X$inc_med <- as.numeric(X$inc_lowmed & !X$inc_low)
X$attend_low <- as.numeric(df$attend <= 2)
X$attend_lowmed <- as.numeric(df$attend <= 3)
#X$attend_medhigh <- as.numeric(!X$attend_low)
X$attend_high <- as.numeric(!X$attend_lowmed)
#X$attend_med <- as.numeric(X$attend_lowmed & !X$attend_low)
X$polint_low <- as.numeric(df$polint <= .5)
X$polint_high <- as.numeric(!X$polint_low)
X$inteff1_low <- as.numeric(df$inteff1 <= .25)
X$inteff1_lowmed <- as.numeric(df$inteff1 <= .5)
#X$inteff1_medhigh <- as.numeric(!X$inteff1_low)
X$inteff1_high <- as.numeric(!X$inteff1_lowmed)
#X$inteff1_med <- as.numeric(X$inteff1_lowmed & !X$inteff1_low)
X$inteff2_low <- as.numeric(df$inteff2 <= .25)
X$inteff2_lowmed <- as.numeric(df$inteff2 <= .5)
#X$inteff2_medhigh <- as.numeric(!X$inteff2_low)
X$inteff2_high <- as.numeric(!X$inteff2_lowmed)
#X$inteff2_med <- as.numeric(X$inteff2_lowmed & !X$inteff2_low)
X$motivation_low <- discretize(df$motivation, 1/3)
X$motivation_lowmed <- discretize(df$motivation, 2/3)
X#$motivation_medhigh <- as.numeric(!X$motivation_low)
X$motivation_high <- as.numeric(!X$motivation_lowmed)
#X$motivation_med <- as.numeric(X$motivation_lowmed & !X$motivation_low)
Y <- dep$vote18
feats <- colnames(X)
split <- strsplit(cond, "_")[[1]]
if (tail(split, 1) != "neg") {  # if not negation, then return original
return(cond)
} else {
fg <- split[1]
val <- split[length(split)-1]
ind <- which(opp==val, arr.ind = T)
if (length(ind) > 0) {
for (i in 1:nrow(ind)) {
row <- ind[i, 1]
col <- ifelse(ind[i, 2]==1, yes=2, no=1)  # other column is opposite value
feat <- paste(fg, opp[row, col], sep="_")
if (feat %in% feats) {  # check if this opposite value is one of the possible features
return(feat)
}
}
}
}
feat
split <- strsplit(cond, "_")[[1]]
tail(split, 1) != "neg"
fg <- split[1]
val <- split[length(split)-1]
ind <- which(opp==val, arr.ind = T)
length(ind) > 0
row <- ind[i, 1]
col <- ifelse(ind[i, 2]==1, yes=2, no=1)  # other column is opposite value
ind
row
col
i
i <- 1
row <- ind[i, 1]
col <- ifelse(ind[i, 2]==1, yes=2, no=1)  # other column is opposite value
feat <- paste(fg, opp[row, col], sep="_")
feat
cond <- "age_lowmed"
split <- strsplit(cond, "_")[[1]]
fg <- split[1]
val <- split[length(split)-1]
ind <- which(opp==val, arr.ind = T)
row <- ind[i, 1]
col <- ifelse(ind[i, 2]==1, yes=2, no=1)  # other column is opposite value
fg <- split[1]
val <- split[length(split)-1]
ind <- which(opp==val, arr.ind = T)
ind
split <- strsplit(cond, "_")[[1]]
split
cond <- "age_lowmed_neg"
split <- strsplit(cond, "_")[[1]]
fg <- split[1]
val <- split[length(split)-1]
ind <- which(opp==val, arr.ind = T)
row <- ind[i, 1]
col <- ifelse(ind[i, 2]==1, yes=2, no=1)  # other column is opposite value
feat <- paste(fg, opp[row, col], sep="_")
i
coln
col
row
ind
opp[row, col]
paste(fg, opp[row, col], sep="_")
feat <- paste(fg, opp[row, col], sep="_")
feat %in% feats
feat
allFeatures <- colnames(X)
# names of features (repeated according to multiplicity), and their values
# needed for simplifyFeature (changes _neg to positive if only two possible values)
feat_split = strsplit(allFeatures, "_")
feat_names <- c()
feat_values <- c()
for(i in 1:length(feat_split)){
feat_names <- append(feat_names, feat_split[[i]][1])
feat_values <- append(feat_values, feat_split[[i]][2])
}
feat_split
feat_values[is.na(feat_values)]
feat_values[is.na(feat_values)] <- 1
feat_values
feat_names
# find most frequent rules of each length
byLen <- vector(mode="list", length=maxLen) # rules grouped by length
maxLen <- 3
#save(out, file="data/BRS output/vote_pois.rda")
load("data/BRS output/vote_pois.rda")
minProp = .05
simplify <- F
freq_featGroup <- sort(table(allFeatGroups), decreasing = TRUE)
amat_group <- matrix(0, nrow = length(names(freq_featGroup)), ncol = length(names(freq_featGroup)), dimnames = list(names(freq_featGroup),names(freq_featGroup))) # Empty adjacency matrix
for(i in 1:length(allRuleSets)){ # for ith rule set
ruleSet <- allRuleSets[[i]]
for(j in 1:length(ruleSet)){# for jth rule
rule <- ruleSet[[j]]
# Check that there are more than 1 rule
if(length(rule) > 1){
# Connections between rules
for(k in 1:(length(rule)-1)){ # for kth feature in rule, up to 2nd to last feature
feat1 <- strsplit(rule[k], "_")[[1]][1]
for(l in (k+1):length(rule)){ # for each rule after the kth rule
feat2 <- strsplit(rule[l], "_")[[1]][1]
# Order by frequency (link goes from most to least frequent; alphabetical if even frequency)
if(freq_featGroup[feat1] > freq_featGroup[feat2]){
feats <- c(feat1, feat2)
} else if(freq_featGroup[feat2] > freq_featGroup[feat1]){
feats <- c(feat2, feat1)
} else{
feats <- sort(c(feat1, feat2))
}
amat_group[feats[1], feats[2]] <- amat_group[feats[1], feats[2]] + 1
#amat_group[feat2, feat1] <- amat_group[feat2, feat1] + 1 # Comment out to eliminate duplicate entries
}
}
# if only 1 rule, then increment entry w/ itself as row and col
} else {
feat1 <- strsplit(rule[1], "_")[[1]][1]
amat_group[feat1, feat1] <- amat_group[feat1, feat1] + 1
}
}
}
allRuleSets <- out[[1]]
# find most frequent rules of each length
byLen <- vector(mode="list", length=maxLen) # rules grouped by length
for(i in 1:length(allRuleSets)){ # loop through all rule sets
ruleSet <- allRuleSets[[i]]
for(j in 1:length(ruleSet)){ # loop through all rules in rule set
rule <- sort(ruleSet[[j]]) # sort alphabetically
if(simplify){
for(k in 1:length(rule)){ # loop through each condition in the rule
rule[k] <- simplifyCondition(rule[k], opp, allFeatures) # simplify if possible
}
}
len <- length(rule)
byLen[[len]] <- rbind(byLen[[len]], rule) # append to group of rules of same length
}
}
byLen
simplify <- T
# find most frequent rules of each length
byLen <- vector(mode="list", length=maxLen) # rules grouped by length
for(i in 1:length(allRuleSets)){ # loop through all rule sets
ruleSet <- allRuleSets[[i]]
for(j in 1:length(ruleSet)){ # loop through all rules in rule set
rule <- sort(ruleSet[[j]]) # sort alphabetically
if(simplify){
for(k in 1:length(rule)){ # loop through each condition in the rule
rule[k] <- simplifyCondition(rule[k], opp, allFeatures) # simplify if possible
}
}
len <- length(rule)
byLen[[len]] <- rbind(byLen[[len]], rule) # append to group of rules of same length
}
}
## Helper functions
#' Function that simplifies feature if possible
#' @param originalFeature feature to simplify
#' @param featureNames vector of all feature names, repeated according to multiplicity
#' @param featureValues vector of all values corresponding to features (same order as featureNames)
#' @return name of feature to use
#' Original feature if no _neg suffix
#' if _neg suffix: original feature and value if none or multiple alternative values, other feature value if exactly one alternative
simplifyFeature <- function(originalFeature, featureNames, featureValues){
split_feat <- strsplit(originalFeature, "_")[[1]]
name <- split_feat[1]
value <- split_feat[2]
# Check if _neg and if there is exactly one other possible value
if(tail(split_feat, 1) == "neg" & (sum(featureNames==name) == 2)){
# Return other feature and value
return(paste(name, featureValues[featureNames==name & featureValues!=value], sep="_"))
}
else {
return(originalFeature)
}
}
#'
simplifyCondition <- function(cond, opp, feats){
split <- strsplit(cond, "_")[[1]]
if (tail(split, 1) != "neg") {  # if not negation, then return original
return(cond)
} else {
fg <- split[1]
val <- split[length(split)-1]
ind <- which(opp==val, arr.ind = T)
if (length(ind) > 0) {
for (i in 1:nrow(ind)) {
row <- ind[i, 1]
col <- ifelse(ind[i, 2]==1, yes=2, no=1)  # other column is opposite value
feat <- paste(fg, opp[row, col], sep="_")
if (feat %in% feats) {  # check if this opposite value is one of the possible features
return(feat)
}
}
}
}
return(cond)  # not one of the possible features
}
#' Get labels for features
#'
#' Get the labels of a features to use in graphs
#'
#' @param feat feature or vector of features to get the label of; should be of the form "feature_value"
#' @param labels_df dataframe of unique feature and corresponding labels; first column is the feature, second column is corresponding label
#' @param neg_label prefix to use for negative features
#' @return label to use for feat
getLabel <- function(feat, labels_df, neg_label){
label <- c()
for(i in 1:length(feat)){
neg <- ""
split_feat <- strsplit(feat[i], "_")[[1]]
if ( tail(split_feat, 1) == "neg" ){
neg <- neg_label
feat[i] <- paste(split_feat[1:(length(split_feat)-1)], collapse="_")
}
label[i] <- paste(neg, labels_df[labels_df[,1]==feat[i],2], sep="")
}
return(label)
}
#' Get the number of cases that satisfy a rule
#'
#' @param rule rule to check: must be in the format feature_value or feature_value_neg
#' @param df data to check
#' @param Y if included, checks that case's Y=y_val
#' @param y_val value Y should take
#' @return number of cases in data that satisfies rule
numCases <- function(rule, df, Y=NULL, y_val=1){
feats <- c() # Features to check
values <- c() # Values of features
for(i in 1:length(rule)){ # Loops through all features in rule to get feature (w/o _neg) and value
feats[i] <- rule[i]
values[i] <- 1
split_feat <- strsplit(feats[i], "_")[[1]]
if ( tail(split_feat, 1) == "neg" ) {
#if(length(split_feat) == 3){ # Checks if _neg
values[i] <- 0
feats[i] <- paste(split_feat[1:(length(split_feat)-1)], collapse="_")
}
}
if(is.null(Y)){
val <- sum(apply(df[,feats] == matrix(rep(values, nrow(df)), ncol=length(values), byrow=T), 1, all)) # Number of cases that satisfy rule
} else { # must satisfy Y
val <- sum(apply(cbind(Y, df[,feats]) == matrix(rep(c(y_val,values), nrow(df)), ncol=(length(values)+1), byrow=T), 1, all)) # Number of cases that satisfy rule and Y
}
return(val)
}
#'
getFeat <- function(rule) {
split_feat <- strsplit(rule, "_")[[1]]
feat <- ifelse(tail(split_feat, 1) == "neg",
yes=paste(split_feat[1:(length(split_feat)-1)], collapse="_"),
no=paste(split_feat, collapse="_"))
return(feat)
}
# find most frequent rules of each length
byLen <- vector(mode="list", length=maxLen) # rules grouped by length
for(i in 1:length(allRuleSets)){ # loop through all rule sets
ruleSet <- allRuleSets[[i]]
for(j in 1:length(ruleSet)){ # loop through all rules in rule set
rule <- sort(ruleSet[[j]]) # sort alphabetically
if(simplify){
for(k in 1:length(rule)){ # loop through each condition in the rule
rule[k] <- simplifyCondition(rule[k], opp, allFeatures) # simplify if possible
}
}
len <- length(rule)
byLen[[len]] <- rbind(byLen[[len]], rule) # append to group of rules of same length
}
}
byLen
rule
rule[k]
# bootstrapped ---------------------
load("sherlock/out/out_vote_sherlock.rda")
allRuleSets <- out[[1]]
# find most frequent rules of each length
byLen <- vector(mode="list", length=maxLen) # rules grouped by length
for(i in 1:length(allRuleSets)){ # loop through all rule sets
ruleSet <- allRuleSets[[i]]
for(j in 1:length(ruleSet)){ # loop through all rules in rule set
rule <- sort(ruleSet[[j]]) # sort alphabetically
if(simplify){
for(k in 1:length(rule)){ # loop through each condition in the rule
rule[k] <- simplifyCondition(rule[k], opp, allFeatures) # simplify if possible
}
}
len <- length(rule)
byLen[[len]] <- rbind(byLen[[len]], rule) # append to group of rules of same length
}
}
byLen
# get top maxRules rules of each length
rules <- vector(mode="list", length=maxLen) ## names of the most frequent rules
freq <- vector(mode="list", length=maxLen) ## frequencies of the most frequent rules
reps <- length(allIndices)
for(len in 1:maxLen){
if (!is.null(byLen[[len]])) {
temp <- as.data.frame(byLen[[len]]) %>% dplyr::group_by_all() %>% dplyr::tally(sort=T) ## group together all columns and count number of times each row (rule) appears
thisFreq <- c(temp[,len+1]/reps)[[1]] # frequency as a proporiton of number of bootstraps
keep <- (thisFreq >= minProp)  # indices of rules that appear sufficiently many time
if ( sum(keep) > 0 ) {
rules[[len]] <- as.data.frame(temp[keep,1:len][1:min(maxRules, sum(keep)),])
freq[[len]] <- thisFreq[keep][1:min(maxRules, sum(keep))]
}
}
}
require(dplyr)
allIndices <- lapply(1:rep, function(x) sample(nrow(df), nrow(df), replace=T))
df <- X
allIndices <- lapply(1:rep, function(x) sample(nrow(df), nrow(df), replace=T))
df
rep <- 100
if ( length(allIndices) == 0 ) {
allIndices <- lapply(1:rep, function(x) sample(nrow(df), nrow(df), replace=T))
}
allIndices <- lapply(1:rep, function(x) sample(nrow(df), nrow(df), replace=T))
# get top maxRules rules of each length
rules <- vector(mode="list", length=maxLen) ## names of the most frequent rules
freq <- vector(mode="list", length=maxLen) ## frequencies of the most frequent rules
reps <- length(allIndices)
length(allRuleSets)
reps <- length(allRuleSets)
for(len in 1:maxLen){
if (!is.null(byLen[[len]])) {
temp <- as.data.frame(byLen[[len]]) %>% dplyr::group_by_all() %>% dplyr::tally(sort=T) ## group together all columns and count number of times each row (rule) appears
thisFreq <- c(temp[,len+1]/reps)[[1]] # frequency as a proporiton of number of bootstraps
keep <- (thisFreq >= minProp)  # indices of rules that appear sufficiently many time
if ( sum(keep) > 0 ) {
rules[[len]] <- as.data.frame(temp[keep,1:len][1:min(maxRules, sum(keep)),])
freq[[len]] <- thisFreq[keep][1:min(maxRules, sum(keep))]
}
}
}
maxRules <- 10
for(len in 1:maxLen){
if (!is.null(byLen[[len]])) {
temp <- as.data.frame(byLen[[len]]) %>% dplyr::group_by_all() %>% dplyr::tally(sort=T) ## group together all columns and count number of times each row (rule) appears
thisFreq <- c(temp[,len+1]/reps)[[1]] # frequency as a proporiton of number of bootstraps
keep <- (thisFreq >= minProp)  # indices of rules that appear sufficiently many time
if ( sum(keep) > 0 ) {
rules[[len]] <- as.data.frame(temp[keep,1:len][1:min(maxRules, sum(keep)),])
freq[[len]] <- thisFreq[keep][1:min(maxRules, sum(keep))]
}
}
}
rules
minProp <- .05
for(len in 1:maxLen){
if (!is.null(byLen[[len]])) {
temp <- as.data.frame(byLen[[len]]) %>% dplyr::group_by_all() %>% dplyr::tally(sort=T) ## group together all columns and count number of times each row (rule) appears
thisFreq <- c(temp[,len+1]/reps)[[1]] # frequency as a proporiton of number of bootstraps
keep <- (thisFreq >= minProp)  # indices of rules that appear sufficiently many time
if ( sum(keep) > 0 ) {
rules[[len]] <- as.data.frame(temp[keep,1:len][1:min(maxRules, sum(keep)),])
freq[[len]] <- thisFreq[keep][1:min(maxRules, sum(keep))]
}
}
}
rules
# calculate coverage statistics
tp <- vector(mode="list", length=maxLen)
fp <- vector(mode="list", length=maxLen)
for(len in 1:maxLen){
if(!is.null(rules[[len]]) && nrow(rules[[len]])>0){
tp[[len]] <- .getTP(rules=rules[[len]], allIndices=allIndices, reps=reps, df=df, Y=Y)
fp[[len]] <- .getFP(rules=rules[[len]], allIndices=allIndices, reps=reps, df=df, Y=Y)
}
}
#' Get proportion of true positives
.getTP <- function(rules, allIndices, reps, df, Y){
stats <- c()
for(i in 1:nrow(rules)){ # Loop through rules
coverage <- c()
for(j in 1:reps){ # Loop through bootstrap samples
ind <- allIndices[[j]]
coverage[j] <- numCases(rule=unlist(rules[i,]), df=df[ind,], Y=Y[ind]) # number of true positives in that bootstrap
}
stats <- rbind(stats,
c(quantile(coverage, .025), median(coverage), quantile(coverage, .975))/length(Y))
}
colnames(stats) <- c("min", "median", "max") # min=.025 quantile, max=.975 quantile
return(data.frame(stats))
}
#' Get proportion of false positives
.getFP <- function(rules, allIndices, reps, df, Y){
stats <- c()
for(i in 1:nrow(rules)){ # Loop through rules
coverage <- c()
for(j in 1:reps){ # Loop through bootstrap samples
ind <- allIndices[[j]]
coverage[j] <- numCases(rule=unlist(rules[i,]), df=df[ind,], Y=Y[ind], y_val=0) # number of false positives in that bootstrap
}
stats <- rbind(stats,
c(quantile(coverage, .025), median(coverage), quantile(coverage, .975))/length(Y))
}
colnames(stats) <- c("min", "median", "max") # min=.025 quantile, max=.975 quantile
return(data.frame(stats))
}
# calculate coverage statistics
tp <- vector(mode="list", length=maxLen)
fp <- vector(mode="list", length=maxLen)
for(len in 1:maxLen){
if(!is.null(rules[[len]]) && nrow(rules[[len]])>0){
tp[[len]] <- .getTP(rules=rules[[len]], allIndices=allIndices, reps=reps, df=df, Y=Y)
fp[[len]] <- .getFP(rules=rules[[len]], allIndices=allIndices, reps=reps, df=df, Y=Y)
}
}
library(BRS)
library(BRS)
library(BRS)
library(BRS)
library(BRS)
library(BRS)
library(BRS)
library(BRS)
?BRS
??BRS
devtools::documents()
install.packages("devtools")
devtools::documents()
devtools::document()
require(devtools)
install()
??agg
??BRS::agg
??BRS
require(BRS)
??agg_BRS
getwd()
install_github("albertchiu/brs")
devtools::install_github("albertchiu/brs")
devtools::install_github("albert-chiu/brs")
library(brs)
reticulate::conda_install(envname = "BRS_conda",
conda="auto",  # check default sequence of locations for conda
packages = c("numpy", "pandas", "scikit-learn", "scipy"),
python_version = "3.6.1")
## Set working directory -----------------------------
rep_path <- "~/Dropbox/QCAplus/replication_JoP/replication/"  # set this to be the replication folder
setwd(rep_path)
## Install BRS function from source and load python ---------------------------
# make sure you have all dependencies installed first
install.packages(c("reticulate", "circlize", "Rtsne"))
install.packages(c("reticulate", "circlize", "Rtsne"))
# install BRS
install.packages("BRS_0.0.0.9006.tar.gz", repos = NULL, type="source")
# Python
reticulate::conda_install(envname = "BRS_conda",
conda="auto",  # check default sequence of locations for conda
packages = c("numpy", "pandas", "scikit-learn", "scipy"),
python_version = "3.6.1")
# install BRS
install.packages("BRS_0.0.0.9006.tar.gz", repos = NULL, type="source")
getwd()
## Set working directory -----------------------------
rep_path <- "~/Dropbox/QCAplus/replication_JoP/replication/"  # set this to be the replication folder
setwd(rep_path)
